---
title: "Projektaufgaben Block 4"
author: "Carlo Michaelis, 573479; David Hinrichs, 572347; Lukas Ruff, 572521"
date: "31 Januar 2017"
documentclass: article
fontsize: 10pt
header-includes:
  - \usepackage{amsthm}
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  - \DeclareMathOperator*{\argmin}{argmin}
  - \usepackage{MnSymbol}
  - \usepackage{bbm}
  - \usepackage{subfig}
  - \usepackage{theoremref}
  - \newtheorem{satz}{Satz}
  - \newcommand{\E}{\mathbb{E}}
  - \newcommand{\Var}{\text{Var}}
  - \newcommand{\tr}{\text{tr}}
output: 
  pdf_document:
    latex_engine: pdflatex
    keep_tex: true
    fig_caption: true
    number_sections: true
---

```{r setup, include=FALSE}
# Load libraries
```

# Markovketten zur Modellierung von Krebswachstum

```{r Read data}
# Read data
P <- as.matrix(read.csv("data/lungcancer.csv"))
nStates <- dim(P)[1]

# Sanity check
apply(P, 1, sum)
```

```{r Mean number of steps for cancer to reach position (Method 1)}
# Method 1
fnMCMeanSteps1 <- function(x, mu, P, tailProb = 0.01){
  # This function computes the mean number of steps needed to reach state x for
  # a Markov chain defined with initial distribution mu and transition matrix P.
  # 
  # Args:
  #   x:        Target state
  #   mu:       Initial distribution
  #   P:        Transition matrix
  #   tailProb: Tail probability to control approximation
  #   
  # Returns:
  #   Expected number of steps to reach state x for the first time
  
  # Step 0
  cumProbs <- mu[x]
  mean <- mu[x] * 0  # symbolic initialization
  
  # Step 1
  tempProb <- sum(mu[-x] * P[-x, x])
  cumProbs <- cumProbs + tempProb
  mean <- mean + tempProb * 1
  
  # Further steps
  PTilde <- diag(length(mu) - 1)  # initialize PTilde
  k <- 2
  
  while (1-cumProbs >= tailProb) {
    PTilde <- PTilde %*% P[-x, -x]  # Update PTilde
    tempProb <- mu[-x] %*% PTilde %*% P[-x, x]  # Get prob. of hitting time k
    cumProbs <- cumProbs + tempProb  # cumulate probability mass
    mean <- mean + tempProb * k  # update mean
    k <- k+1
  }
  
  # Return mean
  return(as.double(mean))
}
```

```{r Test Method 1}
# Define initial distribution (always begin in state 23 (Lung))
mu <- rep(0, nStates)
mu[23] <- 1

# Expected steps to reach certain position
meanStepsBladder <- fnMCMeanSteps1(5, mu, P, tailProb = 10^-5)
meanStepsBrain <- fnMCMeanSteps1(7, mu, P, tailProb = 10^-5)
meanStepsHeart <- fnMCMeanSteps1(17, mu, P, tailProb = 10^-5)
```

```{r Mean number of steps for cancer to reach position (Method 2)}
# Method 2
fnMCMeanSteps2 <- function(x, mu, P, T = 1000){
  # This function computes the mean number of steps needed to reach state x for
  # a Markov chain defined with initial distribution mu and transition matrix P.
  # This method approximates the mean using 10'000 Markov chain simulations with
  # a maximum of T steps per simulation.
  # 
  # Args:
  #   x:  Target state
  #   mu: Initial distribution
  #   P:  Transition matrix
  #   T:  Maximum length of Markov chain
  #   
  # Returns:
  #   Expected number of steps to reach state x for the first time
  
  # Number of states and simulations
  nStates <- length(mu)
  nSim <- 10^4
  
  # Initialize matrix for markov chains
  matSteps <- matrix(nrow = nSim, ncol = T)
  
  # Sample initial state with mu
  matSteps[, 1] <- sample(1:nStates, nSim, replace = TRUE, prob = mu)
  
  # Write sub-function for state-dependend sampling to use with sapply
  fnMCStep <- function(state){
    return(sample(1:nStates, 1, prob = P[state, ]))
  }
  
  # Simulate markov chains
  for (i in 2:T){
    matSteps[, i] <- sapply(matSteps[, i-1], fnMCStep)
  }
  
  # Get steps needed to reach state x the first time for each simulation
  # Again, we use a sub-function that can be used with apply
  fnFirstTime <- function(mc){
    # Args:
    #   mc: markov chain (vector)
    
    return(which(mc == x)[1])  # returns NA, if state x is not reached at all
  }
  
  mean <- mean(apply(matSteps, 1, fnFirstTime), na.rm = TRUE)
  
  # Return mean
  return(mean)
}
```


# Poisson-Prozess

```{r Read Data}
N <- as.matrix(read.csv("data/traffic.csv", header = TRUE))

# Get vector of 96 data points
Nt <- as.vector(t(N[,2:5]))

# Calculate lambda tilde and lambda as function of t
lambdaTildeT <- Nt
lambdaT <- 1.2 * lambdaTildeT
```

```{r Simulate Poisson Traffic}
fnSimulatePoisson <- function(lambda, n) {
  # This function simulates poisson values based on vector of parameters lambda
  # 
  # Args:
  #   lambda:   Vector of parameters for poisson distribution
  #   n:        Number of simulations
  #   
  # Returns:
  #   Simulated vectors as matrix, where every row is a simulation of one day
  #   therefore the matrix as n rows.
  
  # Get random poisson distributed values for n days
  vSimulated <- rpois(length(lambda)*n, lambda)
  
  # Split data into matrix of form: mSplitted[day, quarter-hour]
  # where day goes from 1 to n and quater-hour from 1 to 96
  mSplitted <- t(matrix(vSimulated, nrow=length(lambda), ncol=n))
  
  return(mSplitted)
}

# Define number of simulations
nSimulations = 10000

# Run poisson simulation, based on parameter values from traffic.csv
mSimulation <- fnSimulatePoisson(lambdaT, nSimulations)
```

```{r Evaluate Results}
## Task 1
meanCarsPerDay <- mean(rowSums(mSimulation))

## Task 2
thousandsCar <- NULL
for(i in 1:nSimulations) {
  # Calculate cumulative sums per day (per simulation)
  cumsumDay <- cumsum(mSimulation[i,])
  
  # It's not clear if floor should ne applies only for mean, or also here
  # However, in the end the results seems to be the same
  thousandsCar[i] <- floor(max(which(cumsumDay <= 1000))/4)
}

meanThousandsCar <- floor(mean(thousandsCar))

## Task 3
# Time between 1:30 and 1:45 is at position 7
meanCarsAtNightQuarter <- mean(as.vector(mSimulation[,7]))
# The result is 0, which we can easily explain as lambda is 0 in this timeslot
# More input data, to have a more precise model, would possibly change this

## Task 4/5
maxTrafficPeriodIndices <- NULL
maxTrafficPeriodValues <- NULL
for(i in 1:nSimulations) {
  # Calculate cumulative sums per day (per simulation)
  cumsumDay <- cumsum(mSimulation[i,])
  
  # Initialize new vector
  sumHourlyPeriod <- NULL
  
  # Run from 0.0 to 23.0
  for(j in 1:(length(cumsumDay)-4)) {
    sumHourlyPeriod[j] <- cumsumDay[j+4] - cumsumDay[j]
  }
  
  # Get maximum position and store in vector
  maxTrafficPeriodIndices[i] <- which.max(sumHourlyPeriod)
  maxTrafficPeriodValues[i] <- max(sumHourlyPeriod)
}

par(mfrow = c(1,2))

hist(maxTrafficPeriodIndices,
     breaks = max(maxTrafficPeriodIndices)-min(maxTrafficPeriodIndices),
     main = paste("4) Histogramm bzgl. ", nSimulations, "Simulationen"),
     xlab = "Einst체ndige Periode mit maximalem Traffic", ylab = "H채ufigkeit")
grid()
# where eg. 30 is the time period between 07:15 - 08:15,
# 31 is 07:30 - 08:30, and so on

hist(maxTrafficPeriodValues,
     main = paste("5) Histogramm bzgl. ", nSimulations, "Simulationen"),
     xlab = paste("Anzahl der vorbeifahrende Fahrzeuge in einst체ndiger Periode",
                  "mit maximalem Traffic"),
     ylab = "H채ufigkeit")
grid()
```

# Der betrunkene Vogel


# Geometrische Brownsche Bewegung und Option Pricing



<!--Footnotes-->