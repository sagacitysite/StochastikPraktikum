---
title: "Projektaufgaben Block 4"
author: "Carlo Michaelis, 573479; David Hinrichs, 572347; Lukas Ruff, 572521"
date: "31 Januar 2017"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    latex_engine: pdflatex
    number_sections: yes
  html_document: default
header-includes:
- \usepackage{amsthm}
- \usepackage{amssymb}
- \usepackage{amsmath}
- \DeclareMathOperator*{\argmin}{argmin}
- \usepackage{MnSymbol}
- \usepackage{bbm}
- \usepackage{subfig}
- \usepackage{theoremref}
- \newtheorem{satz}{Satz}
- \newcommand{\E}{\mathbb{E}}
- \newcommand{\Var}{\text{Var}}
- \newcommand{\tr}{\text{tr}}
fontsize: 10pt
documentclass: article
---

```{r setup, include=FALSE}
# Load libraries
library('ggplot2')
library(xtable)
```

# Markovketten zur Modellierung von Krebswachstum

Lade die Übergangsmatrix $P$ aus der Datei `cancer.csv`:

```{r Read data}
# Read transition matrix
P <- as.matrix(read.csv("data/lungcancer.csv"))
nStates <- dim(P)[1]

# Sanity check
apply(P, 1, sum)
```

Um die mittlere Anzahl von Schritten $\E[\tau_x]$ für Position $x \in \{1,\ldots,50\}$ zu approximieren, implementieren wir zwei Methoden. In Methode 1 nutzen wir aus, dass 
\[
  \mathbb{P}(\tau_x = k) = \sum_{i,j \not = x} \tilde{P}_{ij}^{k-1} P_{jx} \mu(i)
\]
gilt, um mittels
\[
  \E[\tau_x] =\sum_{k=0}^\infty k \mathbb{P}(\tau_x = k)
\]
die mittlere Anzahl von Schritten zu approximieren, wobei $\mu$ die Anfangsverteilung und $P$ die Übergangsmatrix ist. $(\tilde{P}_{ij})$ bezeichnet die Übergangsmatrix $P$, wenn die $x$-te Spalte und die $x$-te Zeile von $P$ durch Nullen ersetzt werden, mit $\tilde{P}^{k-1} = \tilde{P}^{k-2}\tilde{P}$.

```{r Mean number of steps for cancer to reach position (Method 1)}
# Method 1

fnMCMeanSteps1 <- function(x, mu, P, tailProb = 10^-3){
  # This function computes the mean number of steps needed to reach state x for
  # a Markov chain defined with initial distribution mu and transition matrix P.
  # 
  # Args:
  #   x:        Target state
  #   mu:       Initial distribution
  #   P:        Transition matrix
  #   tailProb: Tail probability to control approximation
  #   
  # Returns:
  #   Expected number of steps to reach state x for the first time
  
  # Step 0
  cumProbs <- mu[x]
  mean <- mu[x] * 0  # symbolic initialization
  
  # Step 1
  tempProb <- sum(mu[-x] * P[-x, x])
  cumProbs <- cumProbs + tempProb
  mean <- mean + tempProb * 1
  
  # Further steps
  PTilde <- diag(length(mu) - 1)  # initialize PTilde
  k <- 2
  
  while (1-cumProbs >= tailProb) {
    PTilde <- PTilde %*% P[-x, -x]  # Update PTilde
    tempProb <- mu[-x] %*% PTilde %*% P[-x, x]  # Get prob. of hitting time k
    cumProbs <- cumProbs + tempProb  # cumulate probability mass
    mean <- mean + tempProb * k  # update mean
    k <- k+1
  }
  
  # Return mean
  return(as.double(mean))
}
```

In Methode 2 simulieren wir 10.000 Markovketten und approximieren $\E[\tau_x]$ durch Mittelwertbildung. Dabei wählen wir einen maximalen Zeithorizont $T$ und berücksichtigen nur Pfade bei denen die Position $x$ auch erreicht wird.

```{r Mean number of steps for cancer to reach position (Method 2)}
# Method 2

fnMCMeanSteps2 <- function(x, mu, P, T = 1000){
  # This function computes the mean number of steps needed to reach state x for
  # a Markov chain defined with initial distribution mu and transition matrix P.
  # This method approximates the mean using 10'000 Markov chain simulations with
  # a maximum of T steps per simulation.
  # 
  # Args:
  #   x:  Target state
  #   mu: Initial distribution
  #   P:  Transition matrix
  #   T:  Maximum length of Markov chain
  #   
  # Returns:
  #   Expected number of steps to reach state x for the first time
  
  # Number of states and simulations
  nStates <- length(mu)
  nSim <- 10^4
  
  # Initialize vector to hold number of steps taken to reach state x for the
  # first time for each simulated markov chain
  vSteps <- vector(mode = "integer", length = nSim)
  
  # Start simulation of nSim markov chains with a maximum number of T steps
  for (n in 1:nSim){
    # Sample first state
    state <- sample(1:nStates, 1, prob = mu)
    
    for (t in 2:T+1){
      if (state == x){
        # break if state is x
        vSteps[n] <- t-1  # store number of steps
        break
      } else if (t == T+1) {
        # catch if state x has not been reached in T steps with NA
        vSteps[n] <- NA
        break
      }
      
      # sample next state depending on current state
      state <- sample(1:nStates, 1, prob = P[state, ])
    }
  }

  # Return mean
  return(mean(vSteps, na.rm = TRUE))
}
```

```{r Test Methods, cache = TRUE}
# Define initial distribution (always begin in state 23 (Lung))
mu <- rep(0, nStates)
mu[23] <- 1

# Expected number of steps to reach certain positions (Bladder, Brain, Heart)
 
# Method 1
startTime <- Sys.time()
meanStepsBladder1 <- fnMCMeanSteps1(5, mu, P, tailProb = 10^-5)
meanStepsBrain1 <- fnMCMeanSteps1(7, mu, P, tailProb = 10^-5)
meanStepsHeart1 <- fnMCMeanSteps1(17, mu, P, tailProb = 10^-5)
endTime  <- Sys.time()
timeMethod1 <- endTime - startTime

# Method 2
set.seed(42)
startTime <- Sys.time()
meanStepsBladder2 <- fnMCMeanSteps2(5, mu, P, T = 10000)
meanStepsBrain2 <- fnMCMeanSteps2(7, mu, P, T = 10000)
meanStepsHeart2 <- fnMCMeanSteps2(17, mu, P, T = 10000)
endTime  <- Sys.time()
timeMethod2 <- endTime - startTime
```

Methode 1 benötigte **`r round(as.double(timeMethod1, units = "secs"), 1)` Sekunden**, wohingegen Methode 2  **`r round(as.double(timeMethod2, units = "mins"), 1)` Minuten** für die Approximation benötigte. Die Ergebnisse für Blase, Gehirn und Herz sind in folgender Tabelle zusammengefasst:

```{r Results Table, echo = FALSE, results = "asis"}
print(xtable(matrix(c(meanStepsBladder1, meanStepsBrain1, meanStepsHeart1,
                      meanStepsBladder2, meanStepsBrain2, meanStepsHeart2),
                    ncol = 2, dimnames = list(
                      c("Bladder", "Brain", "Heart"),
                      c("Method 1", "Method 2"))
                    ),
             caption = "Expected number of steps to reach position in body."),
      comment = FALSE)
```


# Poisson-Prozess

```{r Read Data}
N <- as.matrix(read.csv("data/traffic.csv", header = TRUE))

# Get vector of 96 data points
Nt <- as.vector(t(N[,2:5]))

# Calculate lambda tilde and lambda as function of t
lambdaTildeT <- Nt
lambdaT <- 1.2 * lambdaTildeT
```

```{r Simulate Poisson Traffic}
fnSimulatePoisson <- function(lambda, n) {
  # This function simulates poisson values based on vector of parameters lambda
  # 
  # Args:
  #   lambda:   Vector of parameters for poisson distribution
  #   n:        Number of simulations
  #   
  # Returns:
  #   Simulated vectors as matrix, where every row is a simulation of one day
  #   therefore the matrix as n rows.
  
  # Get random poisson distributed values for n days
  vSimulated <- rpois(length(lambda)*n, lambda)
  
  # Split data into matrix of form: mSplitted[day, quarter-hour]
  # where day goes from 1 to n and quater-hour from 1 to 96
  mSplitted <- t(matrix(vSimulated, nrow=length(lambda), ncol=n))
  
  return(mSplitted)
}

# Define number of simulations
nSimulations = 10000

# Run poisson simulation, based on parameter values from traffic.csv
mSimulation <- fnSimulatePoisson(lambdaT, nSimulations)
```

```{r Evaluate Results}
## Task 1
meanCarsPerDay <- mean(rowSums(mSimulation))
print(meanCarsPerDay)

## Task 2
thousandsCar <- NULL
for(i in 1:nSimulations) {
  # Calculate cumulative sums per day (per simulation)
  cumsumDay <- cumsum(mSimulation[i,])
  
  # It's not clear if floor should ne applies only for mean, or also here
  # However, in the end the results seems to be the same
  thousandsCar[i] <- floor(max(which(cumsumDay <= 1000))/4)
}

meanThousandsCar <- floor(mean(thousandsCar))
print(meanThousandsCar)

## Task 3
# Time between 1:30 and 1:45 is at position 7
meanCarsAtNightQuarter <- mean(as.vector(mSimulation[,7]))
# The result is 0, which we can easily explain as lambda is 0 in this timeslot
# More input data, to have a more precise model, would possibly change this
print(meanCarsAtNightQuarter)

## Task 4/5
maxTrafficPeriodIndices <- NULL
maxTrafficPeriodValues <- NULL
for(i in 1:nSimulations) {
  # Calculate cumulative sums per day (per simulation)
  cumsumDay <- cumsum(mSimulation[i,])
  
  # Initialize new vector
  sumHourlyPeriod <- NULL
  
  # Run from 0.0 to 23.0
  for(j in 1:(length(cumsumDay)-4)) {
    sumHourlyPeriod[j] <- cumsumDay[j+4] - cumsumDay[j]
  }
  
  # Get maximum position and store in vector
  maxTrafficPeriodIndices[i] <- which.max(sumHourlyPeriod)
  maxTrafficPeriodValues[i] <- max(sumHourlyPeriod)
}

hist(maxTrafficPeriodIndices,
     breaks = max(maxTrafficPeriodIndices)-min(maxTrafficPeriodIndices),
     main = paste("4) Histogramm bzgl. ", nSimulations, "Simulationen"),
     xlab = "Einstündige Periode mit maximalem Traffic", ylab = "Häufigkeit")
grid()
# where eg. 30 is the time period between 07:15 - 08:15,
# 31 is 07:30 - 08:30, and so on

hist(maxTrafficPeriodValues,
     main = paste("5) Histogramm bzgl. ", nSimulations, "Simulationen"),
     xlab = paste("Anzahl der vorbeifahrende Fahrzeuge in einstündiger Periode",
                  "mit maximalem Traffic"),
     ylab = "Häufigkeit")
grid()
```



# Der betrunkene Vogel

In dieser Aufgabe beschäftigen wir uns mit dem Unterschied in State Recurrence zwischen zwei- und dreidimensionalen Random Walks.
Anders gesagt: Ein betrunkener Mensch (dim=2) findet meist nach Hause, ein betrunkener Vogel (dim=3) aber vielleicht nicht.

## Theorie / Theorem von Polyá

Dazu betrachten wir eine brownsche Bewegung $B_t \sim N(0,t)$, die vom Punkt $x$ ausgeht. Wir verwenden $R=3$ und $x=(10,10)^T$ bzw. $x=(10,10,10)^T$. Polyá's Theorem besagt, dass eine brownsche Bewegung unter gewissen Voraussetzungen mit einer fixen Wahrscheinlichkeit jeden Punkt des Raumes erreicht, also auch den Ursprung.
Daher gibt das Theorem auch die Wahrscheinlichkeit an, dass ein betrunkener Mensch (d=2) und ein Betrunkener Vogel (d=3) es von der Bar wieder nach Hause schaffen:

Sei $T_R,_x = inf \{t>0:\|B_t+x\|=R\} $ blabla,
sei $x \epsilon R^d$ mit $\|x\| \ge R^d$.
Dann ist $\mathbb{P}(T_R,_x < \infty) = \left(\frac{R}{\|x\|}\right)^{d-2}$


Damit gilt für den Menschen mit d=2: $\mathbb{P}(T_R,_x < \infty)=\left(\frac{3}{14}\right)^{0} = 1$
und für den Vogel $\mathbb{P}(T_R,_x < \infty) = \frac{3}{14}$, mit $R=3$ und $\|x\|=14$.

Da wir uns im endlichen $t<\infty$ befinden, simulieren wir $r$ in $\lim_{r\to\infty} \mathbb{P}(T_R,_x < r)$


```{r Illustrate drunk bird and human}
# check if library is there
require('ggplot2')

fnRandomWalk <- function(d, x, N, R) {
  # This function generates a random walk of dimension d, starting from x, with N steps,
  # that ends when the distance to the origin is smaller than R
  #
  # Return: dataframe containing the random walk
  
  dfWalk = data.frame(matrix(nrow=N, ncol=d+1))
  
  n=1
  pos=x
  dfWalk[1,1:d] = pos
  dist = sqrt(sum(pos*pos))
  dfWalk[1,d+1] = dist
  
  while(n<N && R<dist) {
    # Thi is the loop handling the random walk
    rstep <- c(round(rnorm(d),2))
    pos = pos+rstep
    dist <- sqrt(sum(pos*pos))
    dfWalk[n+1,1:d] = pos+rstep
    dfWalk[n+1,d+1] = dist
    n = n+1 
  }
  # na.omit ist necessary to handle random walks exiting after n<N (made it home)
  return(na.omit(dfWalk))
}

set.seed(257)
humanWalk <- fnRandomWalk(2, c(10,10), 1000, 3)
birdWalk <- fnRandomWalk(3, c(10,10,10), 1000, 3)
```

## Plots für Menschen und Vogel

Mensch und Vogel besuchen die gleiche Kneipe (die des Vogels liegt auf dem Dach der Bar), und torkeln nach getanem Werk nach Hause:

```{r Human walk, echo=FALSE}
# Plotting human random walk
start <- data.frame(X=10, Y=10, Z=10)
goal <- data.frame(X=0, Y=0, Z=10)
p1 <- ggplot(humanWalk, aes(x=X1, y=X2, color=X3)) +
    geom_path() +
    geom_point(data=start,aes(X,Y),colour='red',size=4) +
    geom_point(data=goal,aes(X,Y),colour='green',size=4)
p1
```

Der Mensch muss sich nur in $R^2$ bewegen,

```{r Bird walk, echo=FALSE}
# Plotting bird random walk
birdWalk <- fnRandomWalk(3, c(10,10,10), 1000, 3)
p2 <- ggplot(birdWalk, aes(x=X1, y=X2, color=X4)) +
    geom_path() +
    geom_point(data=start,aes(X,Y),colour='red',size=4) +
    geom_point(data=goal,aes(X,Y),colour='green',size=4)
p2

```

während der Vogel in $R^3$ Probleme bekommt.


## Monte Carlo

Jetzt simulieren wir den Random Walk für $d=2$ und $d=3$ mit einer Monte Carlo Simulation:

```{r Simulate random walks, cache = TRUE}

set.seed(45791)
walks <- 1000
steps <- 10000
length <- 10000
startpos <- c(10,10,10)
R <- 3

randValsX <- matrix(rnorm(walks*steps,0,sqrt(length/steps)),nrow=walks,ncol=steps)
randValsY <- matrix(rnorm(walks*steps,0,sqrt(length/steps)),nrow=walks,ncol=steps)
randValsZ <- matrix(rnorm(walks*steps,0,sqrt(length/steps)),nrow=walks,ncol=steps)
randValsX[,1] <- startpos[1]
randValsY[,1] <- startpos[2]
randValsZ[,1] <- startpos[3]
randValsX <- t(apply(randValsX,1,cumsum))
randValsY <- t(apply(randValsY,1,cumsum))
randValsZ <- t(apply(randValsZ,1,cumsum))

WalksH <- sqrt((randValsX^2)+(randValsY^2)) < R
WalksB <- sqrt(((randValsX^2)+(randValsY^2)+(randValsZ^2))) < R

fnWalkIn <- function(slice) {
  # This function takes the columns of the matrix with 0-1 values for distance < R or > R
  # and looks for the first 1 in each row. When found, all entries in the remaining row
  # are set to 1, to signify that the walk has already been 'in'
  # Args:
  #   slice: column of the matrix with 0-1 values for out-in on pos i,j
  first <- match(1,slice)
  if(is.finite(first)) {
    slice[first:length(slice)] <- 1
  }
  return(slice)
}

WalksH <- t(apply(WalksH,1,fnWalkIn))
WalksB <- t(apply(WalksB,1,fnWalkIn))

WalksInH <- apply(WalksH,2,sum)
WalksInB <- apply(WalksB,2,sum)

####################################
```

```{r plot MC, echo=FALSE}
H <- qplot(x=1:length(WalksInH), y=WalksInH,geom="line", xlab="", ylab="",
      main="Walks 'home' after x steps")
B <- qplot(x=1:length(WalksInB), y=WalksInB,geom="line", xlab="", ylab="",
      main="Walks 'home' after x steps")
H
B

```

Die y-Achse zeigt den %-Anteil an random walks, die nach Hause führen. Die x-Achse zeigt die Anzahl der gelaufenen Schritte.
Wie aus dem Theorem von Polya ersichtlich, findet der Mensch auch in endlicher Laufzeit mit deutlich höherer Wahrscheinlichkeit nach Hause als der Vogel.
Im Falle $n \to \infty$ konvergiert die "Heimkehrwahrscheinlichkeit" für $d=2$ sogar gegen 1.

```{r Table Convergence Speed, echo = FALSE, results = "asis"}

# The hardcoded values where obtained in more involved simulations too costly to repeat here
#
print(xtable(matrix(c(WalksInH[steps]/walks, 0.7, 0.75,
                      WalksInB[steps]/walks, 0.12, 0.14),
                    ncol = 2, dimnames = list(
                      c("10.000", "100.000", "1.000.000"),
                      c("Mensch", "Vogel"))
                    ),
             caption = "Convergence of Possibility for 'Home'"),
      comment = FALSE)
```

Aufgrund der endlichen Laufzeit der Simulationen ist es nicht möglich die Konvergenz gegen die von Polya gezeigten Grenzen vollständig zu visualisieren. Insbesondere der Random Walk des Menschen erreicht keine Heimkehrwahrscheinlichkeit von 1, zur Abschätzung der Konvergenzgeschwindigkeit kann obenstehende Tabelle dienen.



# Geometrische Brownsche Bewegung und Option Pricing

## Verhalten der geometrischen Brownschen Bewegung

### Erwartungswert und Varianz

Zur Berechnung des Erwartungswertes und der Varianz der geometrischen Brownschen Bewegung wird die momenterzeugende Funktion der Normalverteilung verwendet

\begin{equation}
\label{eq:momerz}
\mu_X(s) = \E[\exp(sX)] = \exp\left( \mu s + \frac{1}{2} \sigma^2 s^2 \right),
\end{equation}

wobei die Lösung der geometrischen Brownschen Bewegung gegeben ist, als

$$
X_t = X_0 \exp\left( \left(\mu - \frac{\sigma^2}{2} \right) t + \sigma B_t \right),
$$

wobei $B_t$ eine Zufallsvariable ist mit $B_t \sim N(0,t)$. Wir nehmen an, dass $X_0$ deterministisch ist und $t \ge 0$.

Für den Ewartungswert gilt:

\begin{align*}
\E[X_t] &= \E\left[ X_0 \exp\left( \left(\mu - \frac{\sigma^2}{2} \right) t + \sigma B_t \right) \right]\\
&= \E[X_0] \cdot \E\left[ \exp\left(\mu - \frac{\sigma^2}{2} \right) \right] \cdot \E[\exp(\sigma B_t)]\\
&\overset{\eqref{eq:momerz}}{=} X_0 \exp\left(\mu - \frac{\sigma^2}{2} \right) \exp\left( 0 \cdot \sigma + \frac{1}{2} t \sigma^2 \right)\\
&= X_0 \exp\left( \left(\mu - \frac{\sigma^2}{2} \right) + \frac{\sigma^2}{2} t \right)\\
&= X_0 e^{\mu t}
\end{align*}

Und für die Varianz ergibt sich:

\begin{align*}
\Var(X_t) &= \E[X_t^2] - \E[X_t]^2\\
&= \E\left[ X_0^2 \exp\left( 2 \left(\mu - \frac{\sigma^2}{2} \right) t + 2 \sigma B_t \right) \right] - X_0^2 \exp\left( 2\mu t \right)\\
&= X_0^2 \exp\left( 2t \left(\mu - \frac{\sigma^2}{2} \right) \right) \cdot \E[\exp(2\sigma B_t)] - X_0^2 \exp\left( 2\mu t \right)\\
&\overset{\eqref{eq:momerz}}{=} X_0^2 \exp\left( 2t \left(\mu - \frac{\sigma^2}{2} \right) \right) \exp\left( 0 \cdot 2\sigma + \frac{1}{2} t \cdot 4\sigma^2 \right) - X_0^2 \exp\left( 2\mu t \right)\\
&= X_0^2 \exp\left( 2\mu t - \sigma^2 t + 2 \sigma^2 t \right) - X_0^2 \exp\left( 2\mu t \right)\\
&= X_0^2 \exp\left( 2\mu t + \sigma^2 t \right) - X_0^2 \exp\left( 2\mu t \right)\\
&= X_0^2 e^{2 \mu t} \left( e^{\sigma^2 t} -1 \right)\\
\end{align*}

### Grenzwertverhalten

```{r Brownian Motion Function}
fnBrownianMotion <- function(nSim, nSteps, tMax){
  # This function simulates nSim brownian motions with nSteps of length 
  # (tMax/nSteps). That is, the browian motions are of overall length of tMax.
  # 
  # Args:
  #   nSim:   Number of simulations/walks
  #   nSteps: Number of steps in each walk
  #   tMax:   Overall length of each walk
  #   
  # Returns:
  #   A matrix with nSim rows and nSteps columns, i.e. each row is the simulation
  #   of one brownian motion.
  matSteps <- matrix(rnorm(nSim*nSteps, 0, tMax/nSteps), 
                     nrow = nSim, ncol = nSteps)
  return(t(apply(matSteps, 1, cumsum)))
}
```

Für eine Überprüfung der Grenzwerte, werden die drei Fälle simuliert. Dabei werden jeweils `nSteps` Schritte betrachtet und `nSim` Simulationen. Übergeben werden außerdem die entsprechenden Parameter $\mu$ und $\sigma$.

```{r Plot Geometric Brownian Motion for different parameters, cache = TRUE}

fnGeometricBrown <- function(nSim, nSteps, vecMu, vecSigma) {
  # This function simulates for every combination of parameters mu and sigma
  # nSim geometric brownian motions with nSteps of length 1.
  # The results are plotted, including mean Brownian.
  # 
  # Args:
  #   nSim:     Number of simulations
  #   nSteps:   Number of steps in simulation
  #   vecMu:    Vector of mu parameters
  #   vecSigma: Vector of sigma parameters
  #   
  # Returns:
  #   Noting, just creates plots
  
  # Fix start value at 1
  X0 <- 1
  # Obtain length of parameter vectors
  nPars <- length(vecMu)
  
  # One time series plot for every parameter combination
  for(i in 1:nPars) {
    # Get Brownian
    matBM <- fnBrownianMotion(nSim, nSteps, nSteps)
    # Calculate Geometric Brownian
    matX <- X0 * exp((vecMu[i]-0.5*vecSigma[i]^2)*(1:nSteps) + vecSigma[i]*t(matBM))
    
    # Plot all Geometric Brownian
    ts.plot(matX, ylim = c(0,max(matX)), xlab = "steps",
            main = bquote(mu ~ "=" ~ .(vecMu[i]) ~ "/" ~ sigma^2 ~ "=" ~ .(vecSigma[i])),
            col = rgb(63/255, 81/255, 181/255, alpha = 0.15))
    # Add mean of all Geometric Brownians
    lines(rowMeans(matX), lwd = 1.5)
    cat('\r\n\r\n')
  }
  
}

nSim <- 500
nSteps <- 1000
vecMu = c(-0.00245, 0.00005, 0.00255)
vecSigma = c(0.01, 0.01, 0.01)

# Check if 
vecMu-(vecSigma^2/2)

# Rund and plot simulations
fnGeometricBrown(nSim, nSteps, vecMu, vecSigma)
```

Die Plots in der Abbildung zeigen die Fälle $\mu - \frac{\sigma^2}{2} = -0,0025$ (links), $\mu - \frac{\sigma^2}{2} = 0$ (mitte) und $\mu - \frac{\sigma^2}{2} = 0,0025$ (rechts) für jeweils `r nSteps` Schritte. Die schwarze Linie markiert den Mittelwert der `r nSim` Durchgänge, im Titel der Plots angegeben sind jeweils die gewählten Parameter $\mu$ und $\sigma^2$.

## Arbitrage-freier Preis einer europäischen Call-Option

Black und Scholes (1973) modellieren $X_t$, den Preis eines Wertpapiers zum Zeitpunkt $t$, durch eine geometrische Brownsche Bewegung. Der arbitrage-freie Preis $C$ einer europäischen Call-Option mit Ausübungszeit $T$ und Ausübungspreis $K$ ist dann gegeben durch
$$
  C = e^{-rT}\E^*[(X_T - K)_+],
$$
wobei $r > 0$ die risikolose Zinsrate und $X_T$ unter dem Maß $\mathbb{P}^*$ eine geometrische Brownsche Bewegung mit Parametern $\mu = r$ und $\sigma$ ist. \\

Im Folgenden seien $T=1$, $r = 0.04$, $\sigma = 0.2$ und $X_0 = K = 100$. \\
```{r Set parameter}
# Set parameter of geometric brownian motion and call option
TCall <- 1
r <- 0.04
sigma <- 0.2
X0 <- 100
K <- 100
C <- list()
mu <- r
```

Nach der expliziten Formel, die von Black und Scholes 1973 gezeigt wurde, folgt für den arbitrage-freien Preis $C$:

```{r Black and Scholes solution}
# Black-Scholes
d1 <- 1/(sigma*sqrt(TCall)) * (log(X0/K)+(r+(0.5*sigma^2))*TCall)
d2 <- d1-sigma*sqrt(TCall)
C$BlackScholes <- X0*pnorm(d1) - K*exp(-r*TCall)*pnorm(d2)
```

Als zweite Methode wollen wir $C$ durch Simulation von $(X_t)_{0\leq t\leq1}$ mittels der exakten Lösung der geometrischen Brownschen Bewegung, d.h.\ 
$$
  X_t = X_0 \exp\left(\left(\mu-\frac{\sigma^2}{2}\right)t + \sigma B_t\right),
$$
mit Hilfe von Monte-Carlo-Simulationen berechnen. Aufgrund der exakten Lösung für $X_t$ müssen wir lediglich die Brownsche Bewegung $B_t$ simulieren.

```{r MC Simulation with exact formula}
# Simulate brownian motions
nSim <- 10000
nSteps <- 1000
matBM <- fnBrownianMotion(nSim, nSteps, TCall)

# Compute price processes using exact solution of SDE
times <- seq(TCall/nSteps, TCall, 1/nSteps)
matX <- t(X0 * exp((mu-0.5*sigma^2)*times + sigma*t(matBM)))

# Get MC approximation of arbitrage-free price C
payouts <- matX[, nSteps] - K
payouts[payouts <= 0] <- 0

C$MC <- exp(-r) * mean(payouts)

```


```{r Geometric Brownian Motion MC}
############## Monte Carlo
# walks <- 1000
# steps <- 100
# TCalls <- c(seq(0.01,1,1/steps))
# 
# randValsBrown <- matrix(rnorm(walks*steps,0,TCalls/steps),nrow=walks,ncol=steps)
# randValsBrown <- t(apply(randValsBrown,1,cumsum))
# mu <- r
# X_t <- X0*exp((mu-0.5*sigma^2)*TCalls+sigma*randValsBrown)
# 
# expVals <- (X_t - K)
# ######
# rep.row<-function(x,n){
#    matrix(rep(x,each=n),nrow=n)
# }
# TCalls <- rep.row(TCalls,walks)
# ######
# smth <- exp(-r*TCalls)/(walks)*expVals
# smth[smth<0] <- 0
# C$MC <- apply(smth/walks,2,sum)

## Euler
#### confusing formula on slides
#X_k <- X_k_1 + mu*((k-1)*T)




C$Euler <- NULL
## plotting
plot(C$MC)
abline(h=C$BlackScholes,col='red')

```


Die Black-Scholes Formel [Formel] ergibt...

Die MC Simulation ...

Das Euler-Schema...


<!--Footnotes-->